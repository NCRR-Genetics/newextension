# Data management and wrangling {#wrangling}

![](https://img.shields.io/badge/document%20status-in%20progress-orange?style=flat-square)

> When in RStudio, quickly jump to this page using `r3::open_data_wrangling()`.

**Session objectives**:

1. Learn the difference between "messy" and "tidy" data 
and how to create tidy data to simplify your analysis.
1. Perform simple transformations and subsetting of datasets, such as:
    - Subset specific columns and rows of a dataset (with `filter()`and `select()`).
    - Sort rows of a dataset by a specific column (with `arrange()`).
    - Create new or transform existing columns in a dataset (with `mutate()`).
    - Calculate simple data summaries (with `summarize()`).
1. Learn about and apply the "split-apply-combine" method for doing analyses
(with `group_by()` and `summarize()`).
1. Know the difference between "long" and "wide" data 
and how to convert between them by "pivotting" (with `pivot_longer()`
and `pivot_wider()`).
1. Write "tidier" and more readable code by using the pipe (`%>%`) operator.


### Expected learning

For the final exercise of this session, you will try to get the data from the
original data (using NHANES) to the table below. By using the code in this
session, you will have acheived our learning expectations.

The final exercise will be to get this data:

```{r nhanes-data}
NHANES
```

To look like this:

```{r nhanes-output, echo=FALSE}
NHANES %>% 
    mutate(MoreThan5DaysActive = if_else(PhysActiveDays >= 5, TRUE, FALSE)) %>% 
    select(SurveyYr, Gender, Age, Poverty, BMI, BPSysAve, BPDiaAve, TotChol,
           DiabetesAge, nBabies, MoreThan5DaysActive, AlcoholDay) %>% 
    rename(TotalCholesterol = TotChol, 
           NumberOfBabies = nBabies, 
           DrinksOfAlcoholInDay = AlcoholDay, 
           AgeDiabetesDiagnosis = DiabetesAge) %>% 
    filter(Age >= 18, Age <= 75) %>% 
    gather(Measure, Value, -SurveyYr, -Gender) %>% 
    group_by(SurveyYr, Gender, Measure) %>% 
    summarise(Mean = round(mean(Value, na.rm = TRUE), 2)) %>% 
    arrange(Measure, Gender, SurveyYr) %>% 
    spread(SurveyYr, Mean) %>% 
    kable(caption = "Mean values of characteristics for women and men between 18-75 years of age at each of the two survey years.")
```

## Managing and working with data in R

Recall that:

- You should **never** edit your raw data (should be in `data-raw/` folder)
- Only work with your raw data using R code 
- Save the edited data as another dataset (should be in `data/` folder)
- Document and comment as best you can to help you remember
    - But, let the code speak for itself (e.g. keep it simple, have intermediate and descriptive steps)
    
In data "wrangling"/"munging"/managing, most tasks can be broken down into only
a few simple "verbs" (actions), as listed in the table.

```{r, echo=FALSE}
tibble::tribble(
    ~Tasks, ~Examples, ~Function,
    "Choosing columns", "Remove columns related to data entry, such as name of person entering data.", "select()",
    "Renaming columns", "Changing a column name from 'Q1' to 'ParticipantName'.", "rename()",
    "Transforming or modifying columns", "Multiplying a column's values; taking the log.", "mutate()",
    "Subsetting/filtering out rows/observations", "Keeping rows with glucose values above 4.", "filter()",
    "Sorting/re-arranging rows", "Show rows with the smallest value at the top.", "arrange()",
    "Converting from wide to long form", "One row per participant to multiple participants per row (repeated measures).", "pivot_longer()",
    "Converting from long to wide form", "Multiple rows per participant (repeated measures) to one participant per row.", "pivot_wider()",
    "Calculating summaries on the data", "Calculating the maximum, median, and minimum age.", "summarise()",
    "Running analyses by group", "Calculate means of age by males and females.", "group_by() with summarise()"
) %>% 
    kable(caption = "Data wrangling task, an example of the task, and the functions to use for data wrangling.")
```

Wrangling here is used in the sense of maneuvering, managing, controlling, and
turning your data around to better understand it and to prepare it for later
analyses. The packages dplyr and tidyr provide easy tools for most common data
manipulation tasks. For dplyr, it is built to work directly with data frames and
has an additional feature to interact directly with data stored in an external
database, such as in SQL. Working with databases is powerful as you can work
with massive datasets (100s of GB), more than your computer could normally
handle. This won't be covered, but see this [resources from Data
Carpentry](https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html))
to learn more.

A **tip** when doing complicated wrangling and you get the data to a form that you
like and will use often: Save it as an "output" dataset in the `data/` folder so
you can easily use it again later rather than run the wrangling code everytime.

## Loading the packages and dataset

We're going to use the US [NHANES] dataset. There is an [NHANES package] that
contains a teaching version of the original dataset, so we'll use that for this
lesson. First, make sure the R Project you created previously is open. Then open
the `R/wrangling-session.R` script to start typing out the next code. We'll use
this file to write the code for this session (but not for the exercises).

[NHANES]: https://www.cdc.gov/nchs/nhanes/index.htm
[NHANES package]: https://CRAN.R-project.org/package=NHANES

```{r, message=FALSE, warning=FALSE}
# Load up the packages
# tidyverse contains the dplyr and tidyr packages
library(tidyverse)
library(NHANES)

# Briefly glimpse contents of dataset
glimpse(NHANES)
```

### Exercise: Become familiar with the dataset

Time: 10 min

Take the time to get familiar with the NHANES dataset. Create a new R script
by typing in the console `usethis::use_r("exercises-wrangling")`. Then copy the
code below into the file and replace the `___` with the `NHANES` dataset. Run
each line of code by typing `Ctrl-Enter`.

```{r, eval=FALSE}
# Load the packages
library(tidyverse)
library(NHANES)

# Check column names
colnames(___)

# Look at contents
str(___)
glimpse(___)

# See summary
summary(___)

# Look over the dataset documentation
?___
```

<details><summary><strong>Click for a possible solution</strong></summary>
<p>

```{r, eval=FALSE}
# load the packages
library(tidyverse)
library(NHANES)

# Check column names
colnames(NHANES)

# Look at contents
str(NHANES)
glimpse(NHANES)

# See summary
summary(NHANES)

# Look over the dataset documentation
?NHANES
```

</p>
</details>

## "Messy" vs. "tidy" data

The concept of "tidy" data was popularized in an [article] by Hadley Wickham
and described more in the [Tidy Data chapter] of the R for Data Science online
book. A tidy dataset is when:

- Each variable has its own column.
- Each observation has its own row
- Each value has its own cell

[article]: http://www.jstatsoft.org/v59/i10/paper.

Looking at these example datasets, think about why each is "tidy" or "messy". 
What do you notice between the tidy versions and the messier versions?

```{r}
# Datasets come from tidyr
# Tidy:
table1
# Tidy:
table2
# Messier:
table3
# Messy:
table4a
# Messy:
table4b
```

In the tidy versions, `table1` and `table2` have columns that describe their values
(e.g. population is population size), each row is unique (e.g. first row is for 
values from Afghanistan from 1999), and each cell is an explicit value
representative of its column and row. On the other hand, `table3` is not tidy 
because the `rate` column values are a composite of two other column values
(cases and population), when it should be a single number (a percent). Both
`table4a` and `table4b` have columns with ambiguous values inside... what does
values in the `1999` column contain? You can't tell from the data.

Tidy data has a few notable benefits:

1. Time spent preparing your data to be tidy from the beginning can save days
of frustration in the long run.
2. "Tidy data" is a conceptual framework that allows you to easy build off and
wrangle data in simpler and easy to interpret ways, especially when using the
tidyverse packages.

From the concept of tidy data also comes the concept of tidy code. By using
"verbs" (R functions), chaining them together in "sentences" (in a sequential
pipeline), you can construct meaningful and readable code that, in more plain
English, describes what you are doing to the data.

## `%>%`: The pipe operator

A key component of the tidy data and tidy code concept is the use of the `%>%`
operator. This operator allows you to "pipe" the output from one function to the
input of another function, thus allowing you to easily chain functions together
into "sentences". So, instead of nesting functions (reading from the inside to
the outside), the idea of piping is to read the functions from left to right.
This can help clarify and break down complex data processing workflows.

```{r}
# These two ways are the same
colnames(NHANES)
NHANES %>% 
    colnames()

# Standard R way of "chaining" functions together
glimpse(head(NHANES))

# The pipe way of chaining
NHANES %>% 
    head() %>% 
    glimpse()
```

## `mutate()`: Transforming or adding variables

When you need to add a new column or modify an existing one, you can use the
`mutate()` function. Get it, mutate as in to change :wink:

```{r}
# Modify an existing variable
NHANES %>%
    mutate(Height = Height / 100)

# Or create a new variable based on a condition
NHANES %>%
    mutate(HighlyActive = if_else(PhysActiveDays >= 5, "yes", "no"))

# Create or replace multiple variables by using the ","
NHANES %>%
    mutate(new_column = "only one value",
           Height = Height / 100)

# Create new variable with existing variables and save the changes
NHANES_update <- NHANES %>%
    mutate(UrineVolAverage = (UrineVol1 + UrineVol2) / 2)
```

Use the table below as a reference for logical conditions you can use in the
`if_else` function.

```{r logic-operators, echo=FALSE}
tibble::tribble(
    ~Operator, ~ Description,
    "<", "less than",
    "<=", "less than or equal to",
    ">", "greater than",
    ">=", "greater than or equal to",
    "==", "equal to",
    "!=", "not equal to",
    "!x", "Not x",
    "x | y", "x OR y",
    "x & y", "x AND y"
) %>% 
    kable(caption = "Logical operators in R.")
```

### Exercise: Piping, transforming, and adding

Time: 10 min

Here's a chance to practise. Again, using the `exercises-wrangling.R` script in
the `R` folder, take the code below and replace the `___` with the appropriate
variable names. Complete the tasks below. (Suggestion: Create a new "Section"
in the script for this exercise via `Ctrl-Shift-R`).

1. Create a new variable called "UrineVolAverage" by calculating the average
urine volumne (from "UrineVol1" and "UrineVol2").
2. Modify/replace the "Pulse" variable to beats per second (currently is beats per minute).
3. Create a new variable called "YoungChild" when age is less than 6 years.

```{r, eval=FALSE}
# Check the names of the variables
colnames(NHANES)

# Pipe the data into mutate function and:
NHANES_modified <- ___ %>% # dataset
    mutate(
        # 1. Calculate average urine volume
        ___ = ___,
        # 2. Modify Pulse variable
        ___ = ___,
        # 3. Create YoungChild variable using a condition
        ___ = if_else(___, TRUE, FALSE)
    )
NHANES_modified
```

Notice something about the "UrineVolAverage" values?

<details><summary><strong>Click for the solution</strong></summary>
<p>

```{r, eval=FALSE}
# Check the names of the variables
colnames(NHANES)

# Pipe the data into mutate function and:
NHANES_modified <- NHANES %>% # dataset
    mutate(
        # 1. Calculate average urine volume
        UrineVolAverage = (UrineVol1 + UrineVol2) / 2,
        # 2. Modify Pulse variable
        Pulse = Pulse / 60,
        # 3. Create YoungChild variable using a condition
        YoungChild = if_else(Age < 6, TRUE, FALSE)
    )
```

For the "UrineVolAverage" values, they are probably almost entirely `NA` (aka
missing). That's because `NA` values are infectious. See how "UrineVol2" has mostly
`NA` values too? When you calculate something that has `NA`, you get another `NA`.
This is something to be careful about. So always check your calculations!

</p>
</details>

## `select()`: Select specific data by the variables

Sometimes you only need certain variables from a dataset, not all of them. Or
maybe you want to remove certain ones or select variables that match a pattern.
This is when you use `select()`.

```{r}
# Select columns/variables by name, without quotes
NHANES %>%
    select(Age, Gender, BMI)

# To *not* select a variable, us minus (-)
NHANES %>%
    select(-HeadCirc)

# When you have many variables with similar names, use "matching" functions
NHANES %>%
    select(starts_with("BP"), contains("Vol"))
```

For more information on using the pattern functions such as `starts_with()`,
check `?select_helpers`. If you are familiar with [regular expressions], you can
use `matches()`.

[regular expressions]: https://www.rstudio.com/wp-content/uploads/2016/09/RegExCheatsheet.pdf

## `rename()`: Rename specific columns

If you need to rename a column, that's super easy! Use the `rename()` function!

```{r}
# rename using the form "newname = oldname"
NHANES %>% 
    rename(NumberBabies = nBabies)
```

## `filter()`: Filtering/subsetting the data by row

Subsetting/filtering data is a very common activity in data analysis, for example,
keeping only those older than 30 years. Using the `filter()` function lets you
do this. Filtering uses logic for conditions, so refer to the table above for the
logic operators.

**A warning**: Filtering using logic. Humans are really bad at logic. Make sure
that you are very certain that what you think your logic is doing is what the
code is actually doing. Confirm the findings! Lots of mistakes can be made at
this stage, especially with complex logic conditions and filtering. 

```{r}
# when gender is equal to
NHANES %>%
    filter(Gender == "female")

# when gender is *not* equal to
NHANES %>%
    filter(Gender != "female")

# when BMI is equal to
NHANES %>%
    filter(BMI == 25)

# when BMI is equal to or more than
NHANES %>%
    filter(BMI >= 25)

# when BMI is 25 *and* Gender is female
NHANES %>%
    filter(BMI == 25 & Gender == "female")

# when BMI is 25 *or* gender is female
NHANES %>%
    filter(BMI == 25 | Gender == "female")
```

## `arrange()`: Sorting/(re)arranging your data by column

Arranging/sorting your rows is fairly simple with dplyr. Just use `arrange()`!

```{r}
# ascending order by age
NHANES %>%
    arrange(Age) %>% 
    select(Age)

# Other arrange (for reference)
# descending order by rate
NHANES %>%
    arrange(desc(Age)) %>% 
    select(Age)

# ascending order by Age and Gender
NHANES %>%
    arrange(Age, Gender) %>% 
    select(Age, Gender)
```

### Exercise: Filtering and logic, arranging, and selecting

Time: 10 min

Copy and paste the code below into the script `exercises-wrangling.R` (in a new
Section, `Ctrl-Shift-R`). Then start replacing the `___` with the appropriate
code to complete the tasks below:

1. Filter so only those with BMI more than 20 *and* less than 40 *and* keep only
those with diabetes.
2. Filter to keep those who are working ("Work") *or* those who are renting
("HomeOwn") *and* those who do not have diabetes. Select the variables age,
gender, work status, home ownership, and diabetes status.
3. Using sorting and selecting, find out who has had the most number of babies
and how old they are.

```{r, eval=FALSE}
# To see values of categorical data
summary(NHANES)

# 1. BMI between 20 and 40 and who have diabetes
NHANES %>%
    # format: variable >= number
    filter(___ >= ___ & ___ <= ___ & ___ == ___)

# 2. Working or renting, and not diabetes
___ %>%
    filter(___ == ___ | ___ == ___ & ___ == ___) %>% 
    select(___)

# 3. How old is person with most number of children.
___ %>%
    ___(___) %>% 
    ___(___) 
```

<details><summary><strong>Click for a possible solution</strong></summary>
<p>

```{r}
# 1. BMI between 20 and 40 and who have diabetes
NHANES %>%
    # format: variable >= number
    filter(BMI >= 20 & BMI <= 40 & Diabetes == "Yes")

# 2. Working or renting, and not diabetes
NHANES %>%
    filter(Work == "Working" | HomeOwn == "Rent" & Diabetes == "Yes") %>% 
    select(Age, Gender, Work, HomeOwn, Diabetes)

# 3. How old is person with most number of children.
NHANES %>%
    arrange(desc(nBabies)) %>% 
    select(Age, nBabies) 
```

</p>
</details>

## `group_by()`, `summarise()`: Create a summary of the data, alone or by a group(s)

Using `group_by()` on its own does nothing. But, combine it with other functions
like `summarise()` and you can do some very powerful data processing. This
particular combination of commands allows for the [split-apply-combine]
technique to be easily used. Many data analysis tasks can be approached using
this paradigm: split the data into groups, apply some analysis to each group,
and then combine the results together. Using `group_by()` splits the data up and
`summarise()` then applies an analysis and then combines it back together. The
arguments to `group_by()` are the column names that contain the **categorical**
variables for what you want to calculate the summary statistics.

[split-apply-combine]: https://www.jstatsoft.org/article/view/v040i01

Let's first explore using `summarise()` on it's own, which outputs a single value
(e.g. a max or mean). Like `mutate()`, you can add multiple "summaries" by adding
new variables separated by commas.

```{r}
NHANES %>%
    summarise(MaxAge = max(Age, na.rm = TRUE),
              MeanBMI = mean(BMI, na.rm = TRUE))
```

Combine it with `group_by()`.

```{r}
# Grouped by gender
NHANES %>%
    group_by(Gender) %>% 
    summarise(MaxAge = max(Age, na.rm = TRUE),
              MeanBMI = mean(BMI, na.rm = TRUE))

# Grouped by gender and diabetes
NHANES %>%
    group_by(Gender, Diabetes) %>% 
    summarise(MeanAge = mean(Age, na.rm = TRUE),
              MeanBMI = mean(BMI, na.rm = TRUE))
```

## `gather()`: Converting from wide to long form

The tidyr package is a companion package to dplyr and allows for a wide range of
manipulations of the data structure data. For example, sometimes we have data
in the wide form as it is often easier to enter data in wide form. Wide form can
be useful when presenting as tables. But there are usually problems with wide
form data, especially when it comes to analysing it. Look at the table below,
which is in wide form. Wide form data also tends to be a bit "messier" then long
form. For instance, what do the values in the `1999` column mean? Unless you had
a data dictionary, you would not know what those values mean.

```{r table-example-wide-data, echo=FALSE}
kable(table4b, caption = "Example wide form dataset.")
```

The long form on the other hand is usually better suited for analyses and
visualizing, especially when doing [split-apply-combine] techniques. Long form
data also tends to be more *tidy* compared to wide form.

```{r table-example-long-data, echo=FALSE}
kable(table1 %>% select(-cases), caption = "Example long form dataset.")
```

We can get to this from the wide form through wrangling the data like so:

(ref:wide-long) Convert from wide to long. Taken from [R for Data Science](https://r4ds.had.co.nz/tidy-data.html).

```{r image-wide-long, echo=FALSE, fig.cap="(ref:wide-long)"}
# TODO: fix this. Get image directly.
# include_graphics("https://d33wubrfki0l68.cloudfront.net/3aea19108d39606bbe49981acda07696c0c7fcd8/2de65/images/tidy-9.png")
```

To go from wide to long we use `gather` to sweep up a set of columns into one
key-value pair. The **arguments** for `gather` are:

1. The name of a *new* column that contains the original column names
2. The name of a *new* column that contains the values from the original columns
3. The original columns we either want or do not want "gathered" up.

Compare how `table4b` looks normally and then after converting to the long form
with `gather()`.

```{r}
# Original data
table4b

# Convert to long form by stacking population by each year
# Use minue to exclude a variable (country) from being "gathered"
table4b %>% 
    gather(year, population, -country)

# This does the same:
table4b %>%
    gather(year, population, `1999`, `2000`)
```

This can be challenging to conceptually grasp at first. Let's try an example
situation when you may use `gather()`. Let's say you wanted to find out the
means of several characteristics of a population. You could use the `group_by()`
and `summarise()` combination on their own, but another method is using `gather()`
to group by and summarise all the variables at once.

```{r}
# Keep only variables of interest
nhanes_chars <- NHANES %>% 
    select(SurveyYr, Gender, Age, Weight, Height, BMI, BPSysAve)
nhanes_chars

# Convert to long form, excluding year and gender
nhanes_long <- nhanes_chars %>% 
    gather(Measure, Value, -SurveyYr, -Gender)
nhanes_long

# Calculate mean on each measure, by gender and year
nhanes_long %>% 
    group_by(SurveyYr, Gender, Measure) %>% 
    summarise(MeanValue = mean(Value, na.rm = TRUE))
```

Note that summarising by mean can only be done with continuous variables.
Anyway, with the long form, you can do more with less code `r emo::ji("relaxed")`

## Why learn to reformat and reshape data?

Often we receive databases that have been created by others, and in which information is organized in a "messy" way. Some other times, we simply need to reorder the structure of the data to be able to carry out certain data analysis or data visualization that require a specific data structure. 

The tidyverse provides some very powerful packages (e.g. dplyr, tidyr) that can allow for complete reorganization of our data in a few lines of code. Using these packages and their functions have several advantages:

- It makes our lives easier and our work faster because we can jump between different 
formats of our data in an agile and easy-to-track way;

- It makes our work reproducible.

### Wide and long formats

One of the most common operations that we may need to do is to change the way our data is organized from a long (few columns, many rows) to a wide (few rows, many columns) format.

The illustrations below shows how the same information can be represented in a long and a wide format. Notice that the value (a-f) of each variable/key (x,y,z) can be read for each id (1, 2) in both formats.

![*Img: https://github.com/gadenbuie/tidyexplain*](https://github.com/gadenbuie/tidyexplain/raw/master/images/static/png/original-dfs-tidy.png){width=60%}

The functions we want to use for these operations are `pivot_longer()` and `pivot_wider()` from the tidyr package. Those of you already familiar with this package may know the older functions as `spread()` and `gather()`. Although these two functions still work, they are being slowly replaced by the `pivot_**` functions.

### Get familiar with the data

Using the function `View()`, inspect the dataframe `population`, which shows the population census in different countries across multiple years.

Let's load tidyverse:

```{r}
library(tidyverse)
```


```{r, eval = FALSE}
View(population)
```


### Reshape a dataframe from a long to a wide format with `pivot_wider()`

Say that we want to explore how the population varies across years in each country. 
To do this we may want to show each single country as a separate variable (i.e. column). 

This requires reshaping the data so that each single country now listed under the variable `country` 
becomes an individual variable (i.e. column), under which the population numbers, 
now listed under the variable `population`, are listed.

To do so, we will use the function `pivot_wider()` because we want to create 
a wider dataframe with more columns (the single countries), and fewer rows.

We will call this new dataframe `population_wide`.
In the function `pivot_wider()` we want to specify three arguments: 

- the dataframe to work on,
- the argument `names_from`: where we indicate the name of the "long" variable that we will use to create the new "wide" variables 
- the argument `values_from`: the values that we will use to fill the rows of the new variable we created

```{r}
population_wide <- 
  pivot_wider(population, names_from = country, values_from = population) 
population_wide
```

We can run the exact same operation taking advantage of the pipe operator `%>%`
that we showed in the intro session. If the memory is foggy, imagine this operator as an
arrow that connects consecutive functions in a smooth way. 

When using the pipe operator we are indicating that the functions will be applied to the 
dataframe `population`, so we do not need to indicate that into the `pivot_wider()` function arguments.

```{r}
population_wide <- population %>% 
  pivot_wider(names_from = country, values_from = population) 
population_wide
```


#### Exercise 1: Reshaping a dataframe from long to wide format
Use the dataframe `us_rent_income` for this exercise. This dataframe shows the estimated value and the 90%
margin of error for yearly income and monthly rent of each state in the US.

In this case, you want to display the data in wide form to see how estimated income varies across states.
To do so, each state will become a variable (i.e. column) to which the estimated income will be associated

```{r, eval=FALSE}
us_income_wide <- us_rent_income %>% 
  # We are only interested in income and not in rent, 
  # so we will extract these variables of interest from our database
  filter(variable == "income") %>% 
  # We select only the variables of interest to remain in our dataframe
  select(NAME, variable, estimate) %>% 
  pivot_wider(names_from = ______, values_from = _____)
us_income_wide
```

> Advanced: Try selecting both `estimate` and `moe`, and include both in the pivot. Make the name indicate whether the value is the estimate or the moe (e.g. 'moe_Alabama'). 
### Reshape a dataframe from a wide to a long format using `pivot_longer()`

We can also do the opposite: a shift from a dataframe in wide format to a dataframe in long format. 
Let's consider the `population_wide` dataframe that we just created as the starting point. 
Let's say that we want to reshape this data to a format in which all countries are listed under a single variable, e.g. `country_name`, and the population data are listed under a variable called `population_data`. For this operation, we need to use the function `pivot_longer()`.

In this case, we want to specify:

- the argument `names_to`: the name of the new variable under which we want to group our columns, 
- the argument `values_to`: the name of the new variable under which we want to group the values of our variables.

We run this function...

```{r, error=TRUE}
population_wide %>%
  pivot_longer(names_to = "Country", values_to = "Population")
```

... but we get an error message!

This is because we did not specify which columns to shift into a long format.

  > In `pivot_wider()`, if no argument is given to `id_cols` it defaults to select all columns. However, `pivot_longer` has no default for `cols`, and will throw an error if no argument is given.
We could select every column, with the [tidyselect](https://r4ds.had.co.nz/transform.html#select) helper function `everything()`. This function tells `pivot_longer()` to use all the columns in the dataset when converting to long form.

```{r}
population_wide %>%
  pivot_longer(everything(), names_to = "Country", values_to = "Population")
```

This breaks the row-wise relation between year and population, and is clearly not what we want. Instead, we specify that the variable `year` is not to be involved in the reshaping. Columns not involved in the reshape will be copied, to preserve the row-wise relations in the data. 

```{r}
population_wide %>%
  pivot_longer(-year, names_to = "country_name", values_to = "population_data")
```

We use the `-` here for `year` to tell `pivot_longer()` to *not* include (to *exclude*) the column `year` from being converted to long form.

**Notice that** in the function `pivot_longer()` the arguments `names_to` and `values_to` require "" because we are providing names of variables that need to be created. 
Instead, in the function `pivot_wider()` we are giving the arguments `names_from` and `values_from` variables that already exist, hence  the "" are not needed.

#### Exercise 2: Reshaping a dataframe from wide to long format

We will use again the `us_rent_income` dataframe for this exercise.
In this case we want the values of `estimate` and `moe` to be stacked in one single column called `value`, 
while the respective categories of `estimate` and `moe` should be described in a variable called `calculation`

```{r, eval = FALSE}
us_rent_income_long <- us_rent_income %>% 
  # this variable is a nuisance and is not giving information useful to us, 
  # so we will remove it 
  select(-GEOID) %>% 
  # When we want multiple variables, we combine them with `c()`.
  pivot_longer(c(______, ______), names_to = ________, values_to = _________)
us_rent_income_long
```

### `pivot_**` with `group_by()` and `summarize()`

For this example we are going to use the built-in dataframe `storms`

Once again, explore the data using the function `View()`

```{r, eval = FALSE}
View(storms)
```

In this dataframe, information about storms are classified in long format. 
Storms are categorized across years and information on wind, latitude, longitude and pressure 
are presented as columns.

Let's say that we want to see how mean wind speed vary across 
different storm categories (`status`) and across years. 

This means that we want to apply the function `pivot_wider()` to visualize each storm category as a separate variable.

However, before reshaping the dataframe in long form, we need to do some extra work. 
Take another look at the `storms` dataframe. Variables are measured multiple times within each year. 
So if we want to have a mean value of wind speed for each year, we need to use the functions `group_by()` and `summarize()` that we showed in the intro session. 

We are going to call this new dataframe `storm_wide`

First we will calculate the mean value of wind speed for each storm, across years 
and discriminating across storm status

```{r}
storms_sum <- storms %>% 
  #first we select the variable of interest to avoid an overcrowded dataframe
  select(status, year, wind, pressure) %>% 
  #second we tell R according to which criteria we want to summarize our data, i.e. we want to know the mean value of wind speed for each storm according to storm status and year
  group_by(status, year) %>% 
  summarize(mean_wind = mean(wind)) 
storms_sum
```

Now we can reshape the data into a wide format:

```{r}
storms_wide <- storms_sum %>% 
  pivot_wider(names_from = status, values_from = mean_wind)  
storms_wide
```

#### Exercise 3: using `group_by()` and `summarize()` in combination with `pivot_**()` functions to reshape a data frame

Using the dataframe `diamonds` use the functions `group_by()` and `summarize()` in combination with
`pivot_longer()`, `pivot_wider()` to reshape a database in which different values of cut correspond to mean values of x, y, z (tip: you need to use both pivot_longer and pivot_wider!)

The reshaped dataframe should look like this:

```{r, echo = FALSE}
diamonds_means <- diamonds %>% 
  select(cut, x, y, z) %>% 
  group_by(cut) %>% 
  summarize(x_mean = mean(x),
            y_mean = mean(y),
            z_mean = mean(z))
diamonds_long <- diamonds_means %>% 
  pivot_longer(-cut, names_to = "coordinate", values_to = "mean_coord")
diamonds_wide <-  diamonds_long %>% 
    pivot_wider(names_from = cut, values_from = mean_coord)
  
diamonds_wide
```

```{r, eval = FALSE}
diamonds_means <- diamonds %>% 
  select(cut, x, y, z) %>% 
  group_by(___) %>% 
  summarize(x_mean = ____,
            y_mean = ____,
            z_mean = ____)
diamonds_reshaped <- diamonds_means %>% 
  pivot_ ______(____, names_ ___ = __________, values_ ___ = ___________) %>% 
  pivot_ ________(names_ ____ = ________, values_ ____ = __________)
  
diamonds_reshaped
```

> Advanced: Try creating the same dataframe without using `summarize()`. Instead, apply the `mean()` function using the `values_fn` parameter in `pivot_wider()`. How does this work?


## `spread()`: (If time) Converting from long to wide form

You can also convert to wide from long. This is not as commonly done, since most
analyses are better in the long form. But sometimes you may need to have a wide
form. Here you can use `spread()`, which takes three arguments: 1) the data, 2)
the *key* column (or column with identifying information), 3) the *value*
column (the one with the numbers/values). We'll use a pipe so we can ignore the
data argument.

(ref:long-wide) 'Spreading' from long to wide. Taken from the [R for Data Science book](https://r4ds.had.co.nz/tidy-data.html#spreading).

```{r image-long-to-wide, echo=FALSE, fig.cap="(ref:long-wide)"}
# TODO: fix this. Get image directly.
# include_graphics("https://d33wubrfki0l68.cloudfront.net/8350f0dda414629b9d6c354f87acf5c5f722be43/bcb84/images/tidy-8.png")
```

```{r}
# Using a small dataset:
table2

# Convert to wide form
table2 %>% 
    spread(key = type, value = count)
```

The key is the discrete value that will make up the new column names, while the
value will be column that will make up the values of the new columns.

## Final exercise: Group work

Time: ~30 min

This exercise has two aims: to get working on and completing the group project, 
and to get you practicing using the dplyr and tidyr functions we covered today.
First, take maximum 10 min to:

- *As a group*, complete item 2 of the [group assignment](assignment)
(to jump quickly to the assignment, 
run `r3::open_assignment()` in the RStudio Console).
- *Individually*, open your group R project
and complete item 3 of the group assignment.
Follow the appropriate filenaming conventions as we learned in the Project Management
session for the dataset (e.g. don't use spaces, instead use either `-` or `_`).

With the remaining time:

- *As a group*, complete item 4 of the [group assignment](assignment).
Explore the data and *use all the functions* we've covered in this session to
better understand the data you'll work with. 
You can (and probably should) divide exploratory tasks between group members,
so that you have a good understand *as a group* of the data.



