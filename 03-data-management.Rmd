# Data management and wrangling {#wrangling}

> When in RStudio, quickly jump to this page using `r3::open_data_wrangling()`.

**Session objectives**:

1. Learn the difference between "messy" and "tidy" data 
and how to create tidy data to simplify your analysis.
1. Perform simple transformations and subsetting of datasets, such as:
    - Subset specific columns and rows of a dataset (with `filter()`and `select()`).
    - Sort rows of a dataset by a specific column (with `arrange()`).
    - Create new or transform existing columns in a dataset (with `mutate()`).
    - Calculate simple data summaries (with `summarize()`).
1. Learn about and apply the "split-apply-combine" method for doing analyses
(with `group_by()` and `summarize()`).
1. Know the difference between "long" and "wide" data 
and how to convert between them by "pivotting" (with `pivot_longer()`
and `pivot_wider()`).
1. Write "tidier" and more readable code by using the pipe (`%>%`) operator.

## "Messy" vs. "tidy" data

**Take 10 min to read through this *"Messy" vs "tidy" data* section
and the *Managing and working with data in R* section**.

The concept of "tidy" data was popularized in an [article] by Hadley Wickham
and described in more detail in the [Tidy Data chapter] 
of the R for Data Science online book. 

But before we continue with tidy data,
we need to cover something that is related to the concept of "tidy"
and that will come up often in this course: the [tidyverse].
The tidyverse is an ecosystem of R packages that are designed to work well together,
that all follow a strong "[design philosophy]" and common [style guide].
This makes them much easier to use together.
These packages also tend to have excellent, beginner-friendly documentation
and tutorials on learning and using the packages.
We teach the tidyverse because of these reasons.

[tidyverse]: https://www.tidyverse.org/
[design philosophy]: https://design.tidyverse.org/
[style guide]: https://style.tidyverse.org/

Ok, back to "tidy data". A tidy dataset is when:

- Each variable has its own column (e.g. "Body Weight")
- Each observation has its own row (e.g. "Person")
- Each value has its own cell (e.g. "Body weight for a person at a specific date")

[article]: https://www.jstatsoft.org/v59/i10/paper
[Tidy Data chapter]: https://r4ds.had.co.nz/tidy-data.html

Take a look at the example "tidy" and "messy" data frames
(also called "tibbles" in the tidyverse) below.
These datasets come built in with the tidyr package for teaching purpose.
Think about why each is "tidy" or "messy". 
What do you notice between the tidy versions and the messier versions?

```{r}
# Datasets come from tidyr
# Tidy:
table1
# Partly tidy:
table2
# Messier:
table3
# Messy:
table4a
# Messy:
table4b
```

The "most" tidy version is `table1` which has columns that describe their values
(e.g. population is population size), each row is unique (e.g. first row is for 
values from Afghanistan from 1999), and each cell is an explicit value
representative of its column and row. 
`table2` is a "long" version of `table1` so it is partly "tidy", 
but it doesn't satisfy the rule that each variable has a column,
since `count` represents both cases and population size.
On the other hand, `table3` is messy
because the `rate` column values are a composite of two other column values
(cases and population), when it should be a single number (a percent). Both
`table4a` and `table4b` have columns with ambiguous values inside; what does
values in the `1999` column contain? You can't tell from the data.

Tidy data has a few notable benefits:

1. Time spent preparing your data to be tidy from the beginning can save days
of frustration in the long run.
2. "Tidy data" is a conceptual framework that allows you to easily build off 
and wrangle (i.e. "manipulate", "clean up", "manage") data in simpler 
and easy to interpret ways, 
especially when used within the framework of the tidyverse.

The concept of tidy data also gives rise to "tidy code" for wrangling.
By using "verbs" (R functions)
and chaining them together in "sentences" (in a sequential pipeline), 
you can construct meaningful and readable code that describes 
in plainer English what you are doing to the data

## Managing and working with data in R

**Take 5 min and read through this section**.
When working with data, there are a few principles to follow:

- **Never** edit raw data and save it in a separate location 
(could put in the `data-raw/` folder)
    - *Note*: Saving to `data-raw/` depends on how you collected the data 
    and how many collaborators are on your team. 
    You may end up storing and processing the data in another folder as a project
    of its own.
- Only work with your raw data using R code, *don't manually edit it*.
Manual editing doesn't leave a history of what you've done to it,
so you can't go back and see what you've done. 
Always keep a history of any changes you've made to the data,
preferably by using R code.
- Save the edited data as another dataset and store it in the `data/` folder.

When wrangling your data with R code make sure to:

- Document and comment as best you can what you did to your data and why you did
it to help you remember
- Write the code itself to be as descriptive as you can
and to readable enough to understand what is being done to the data.
Keep the code simple: Don't be clever, be clear.
Clear code is easier to understand than some clever code.

In data wrangling, 
most tasks can be expressed by a few simple "verbs" (actions).
Wrangling here is used in the sense of maneuvering, managing, controlling, and
turning your data around to clean it up, to better understand it,
and to prepare it for later analyses. 
The table below lists some common "verbs" from the [dplyr] 
and [tidyr] packages that come from the tidyverse:

```{r table-wrangling-verbs, echo=FALSE}
tibble::tribble(
    ~Task, ~Example, ~Function,
    "Select columns", "Remove data entry columns such as person's name who entered the data.", "`select()`",
    "Rename columns", "Changing a column name from 'Q1' to 'ParticipantName'.", "`rename()`",
    "Transform or modify columns", "Multiplying a column's values or taking the log.", "`mutate()`",
    "Subset/filter rows", "Keeping rows with glucose values above 4.", "`filter()`",
    "Sort rows", "Show rows with the smallest value at the top.", "`arrange()`",
    "Convert data from wide to long", "One row per participant to multiple participants per row (repeated measures).", "`pivot_longer()`",
    "Convert data from long to wide", "Multiple rows per participant (repeated measures) to one participant per row.", "`pivot_wider()`",
    "Calculate summaries of the data", "Calculating the maximum, median, and minimum age.", "`summarise()`",
    "Run an analysis by a group", "Calculate means of age by males and females.", "`group_by()` with `summarise()`"
) %>% 
    knitr::kable(caption = "List of common data wrangling tasks, along with an example and the function used for the wrangling.")
```

The functions above come from the packages [dplyr] and [tidyr]. You will recall that these are packages that are commonly used for data manipulation.

**Tip**: Sometimes you need to do some complicated wrangling to get your data 
in appropriate "shape" to use for later analyses.
To help save some time,
you could save the wrangled data as an "output" dataset in the `data/` folder.
That way, you can easily use it again later rather 
than having to run the wrangling code every time you want to work with the data.

## Load the packages and dataset

We're going to use the US [NHANES] dataset to demonstrate the wrangling functions. 
There is an [NHANES package] that contains a teaching version of the original dataset, 
so we'll use that for this lesson. 
First, make sure the R Project you created previously is open. 
Then open the `R/package-loading.R` script, add the dataset package to the file,
so it looks like:

```{r}
library(tidyverse)
library(NHANES)
```

With the added dataset package, add and commit the changes to the Git history with the RStudio Git Interface.

Then open the `R/wrangling-session.R` script to start typing out the next code. 
We'll use this file to write the code for this session (but not for the exercises).

[NHANES]: https://www.cdc.gov/nchs/nhanes/index.htm
[NHANES package]: https://CRAN.R-project.org/package=NHANES

```{r, message=FALSE, warning=FALSE, eval=-(1:2)}
# Load up the packages
source(here::here("R/package-loading.R"))

# Briefly glimpse contents of dataset
glimpse(NHANES)
```
Add and commit to the Git history with the RStudio Git Interface.

## Exercise: Become familiar with the dataset

Time: 10 min

Take the time to get familiar with the NHANES dataset.

1. Create a new R script by typing in the RStudio Console
`usethis::use_r("exercises-wrangling")`. 
1. Copy the code below and paste it into the new exercise file.
1. Replace the `___` with the `NHANES` dataset. 
1. Run each line of code by typing `Ctrl-Enter`.
1. Add and commit it to the Git history with the RStudio Git Interface.

```{r exercise-familiar-with-data, eval=FALSE}
# Load the packages
source(here::here("R/package-loading.R"))

# Check column names
colnames(___)

# Look at contents
str(___)
glimpse(___)

# See summary
summary(___)

# Look over the dataset documentation
?___
```

<details><summary><strong>Click for the solution</strong></summary>
<p>

```{r solution-exercise-familiar-with-data, eval=FALSE}
# Load the packages
source(here::here("R/package-loading.R"))

# Check column names
colnames(NHANES)

# Look at contents
str(NHANES)
glimpse(NHANES)

# See summary
summary(NHANES)

# Look over the dataset documentation
?NHANES
```

</p>
</details>

## Select specific columns in a dataset

Selecting columns of a dataset is a very common data wrangling task. The function for this task is appropriately called `select()`. You would use `select()` to extract one or more variables in a dataset, to have a closer look at or save as a new data frame to work with. It may be that you wish to explore the clinical characteristics of your study sample, so you may select some basic demographic variables (e.g., `Age` column) and clinical variables (e.g., `Weight` and `Height` columns) to perform these analyses. 

For the input arguments, it takes the dataset as the first argument,
which is the first input position right after the opening bracket `(`,
and then takes the names of the columns you want to select.
Because the argument after the data argument is `...`, 
it means that you can add as many columns as you want, separated by a `,`.

```{r}
# Select one column by its name, without quotes
select(NHANES, Age)

# Select two or more columns by name, without quotes
select(NHANES, Age, Weight, BMI)

# To *exclude* a column, use minus (-)
select(NHANES, -HeadCirc)
```


If some of your columns have similar patterns at the beginning, within, or end,
you can use the helper functions to choose these columns.
Use `?select_helpers` (choose the "Select helpers" option in the menu that pops up)
to read more about these functions and to get help on them. 
Some more useful helpers are:

- `starts_with()`: Select columns that begin with a pattern.
- `ends_with()`: Select columns that end with a pattern.
- `contains()`: Select columns that contain a pattern.

```{r}
# All columns starting with letters "BP" (blood pressure)
select(NHANES, starts_with("BP"))
# All columns ending in letters "Day"
select(NHANES, ends_with("Day"))
# All columns containing letters "Age"
select(NHANES, contains("Age"))
```


For more information on using the pattern functions such as `starts_with()`,
check `?select_helpers`. 

You'll notice that running these functions doesn't actually change the data itself.
When you run a function without assigning it using `<-`,
the only action the function does is to send the output to your screen.
But if you want to create a new dataset with only the columns you selected,
you'll need to assign it to a new object.

The full NHANES dataset is 10,000 individuals (rows) with 76 parameters (columns). Since we are only interested in some of these parameters, we will subset the large dataset and save for future use as a new dataset.

```{r}
# Save the selected parameters as a new dataframe
# Recall the style guide for naming objects
nhanes_small <- select(NHANES, Age, Gender, Height, Weight, BMI, Diabetes, PhysActiveDays)
# View the new dataframe
nhanes_small
```

## Renaming all column names based on style guide

To match the style guide, we should change the column names to be all lower case
and with `_` for spaces between words. There's a package that can do that for us
called [snakecase].

[snakecase]: https://tazinho.github.io/snakecase/

In the Console, type out `snakecase::` and hit Tab. You’ll see a list of
possible functions to use. We want to use the snake case function, so scroll
down and find the `to_snake_case()`. To change all the column names to lower
case, we'll use the function `rename_with()`. This function like the other dplyr
functions, takes the data from the pipe `%>%` as the first argument and takes
another function, which is `to_snake_case()`, for the second argument. Based on
this function, it then renames all columns.

```{r}
nhanes_small <- rename_with(nhanes_small, snakecase::to_snake_case)

# Have a look at the dataframe
nhanes_small
```

## Rename specific columns

Depending on how your data was collected, 
it may have column names that aren't very descriptive.
So you'll probably want to rename them to something more explanatory, which is particularly important if you're sharing your work with others or in an environment where multiple people are working on the same data.
As with `select()`, the rename you use the function called `rename()`.
Like `select()`, `rename()` takes the dataset as the first argument
(first position) and then takes as many renaming arguments as you want
(because the second argument position is `...`).
Renaming takes the form of `newname = oldname`.

```{r}
rename(nhanes_small, sex = gender)
# View dataframe
nhanes_small
```
Notice that the `rename()` function has not altered the `nhanes_small` dataframe. To do this, we need to assign the change to `nhanes_small`:

```{r}
nhanes_small <- rename(nhanes_small, sex = gender)
# View dataframe
nhanes_small
```

Now the column has been renamed from gender to sex. What if you want to select some columns and then rename some of them, do you have to create a new data object every time? No! We can make use of a very powerful tool called piping (with the `%>%` function).

## Chaining functions with the pipe

**Take 5 minutes and read this section** before we continue.

A key component of the tidy data and tidy code concept is making use of the `%>%` operator. You would use the "pipe" operator when you are writing a piece of code with multiple operations/intermediate steps that require you to save/overwrite each step as an object (see below). One advantage of the "pipe" operator is that it will help to ensure that your code is less cluttered with unimportant object names.

This operator allows you to "pipe" the output from one function to the
input of another function, like a plumbing pipe would do for water.
This allows you to easily chain functions together into "sentences".
Let's use an example based on English words for some action. 
This is the English sentence:

> We need some eggs. Drive to the grocery store
and buy up some eggs before coming home from work.

There are basically two actions here ("drive" and "buy")
and four "inputs" ("work", "grocery store", "eggs", "home"),
that are all based on the previous action.
Since an action in R is a function, 
the functions would be `drive()` and `buy()`.
In regular R, if we wanted to chain these functions together, 
we would have to nest them like this:

```{r, eval=FALSE}
drive(buy(drive(at_work, "grocery store"), "eggs"), "home")
```

This is difficult to read. We could also create temporary objects:

```{r, eval=FALSE}
at_grocery_store <- drive(at_work, "grocery store")
got_eggs <- buy(at_grocery_store, "eggs")
at_home <- drive(got_eggs, "home")
```

But this still isn't too "readable", and we are having to re-name each intermediate object with reference to the object before it. The pipe `%>%` operator can really simplify this:

```{r, eval=FALSE}
at_work %>% 
    drive("grocery store") %>% 
    buy("eggs") %>% 
    drive("home")
```

Do you find this more readable and understandable?
We read it like how it would actually be done, in order of the steps taken.

Instead of nesting functions (reading from the inside to the outside), 
the idea of piping is to read the functions from left to right.
This can help clarify and break down complex data processing workflows,
and is the basis for all tidyverse and many other packages.
This is a basic design philosophy of interacting with data when using the tidyverse.

The pipe `%>%` takes the output from the object or function on the left hand side
and puts it into the function of the right hand side.
All input goes into the first position argument of the function.
So with tidyverse packages,
the first position always takes the data,
to make the function usable with the pipe.

**Ok, let's return back together and try this out**. Recall that the
keyboard shortcut for the pipe is `Ctrl-Shift-M`.

```{r}
# These two ways are the same
colnames(nhanes_small)
nhanes_small %>% 
    colnames()
```

Because the pipe automatically takes `nhanes_small`
and puts it into the first position, 
we don't need to type out `nhanes_small` inside `colnames()` when piping.

Let's try the pipe on the `select()` and `rename()` function from the previous section.
Remember, both `select()` and `rename()` take a dataset as the first position,
which makes them pipe-able.

```{r}
NHANES %>% 
    select(nBabies) %>% 
    rename(Number_Babies = nBabies)
```

We can now "read" these actions as:

> Take the NHANES dataset *and then* select the nBabies column 
*and then* rename the nBabies column to Number_Babies.

Before you start the exercise, add and commit to the Git history with the RStudio Git Interface. 

## Exercise: Practice what we've learned

Time: 10 min

In the `exercise-wrangling.R` file, complete these tasks:

1. Copy and paste the below code into the exercise file.
In the `select()` function, 
type in the columns `HomeOwn`, `TVHrsDay`, and `Diabetes`
where the blank space is.

    ```r
    NHANES %>% 
        select(___)
    ```
    
2. Copy and paste the below code and fill out the blanks.
Rename `DiabetesAge` to be `DiabetesAgeOfDiagnosis` and `Gender` to be `Sex` 
(gender is the social construct, while sex is biological).
*Tip*: Recall that renaming is in the form `new = old`.

    ```r
    NHANES %>% 
        rename(___ = ___, ___ = ____)
    ```

3. Re-write this bit of code to use the pipe:

    ```r
    select(NHANES, BMI, contains("Age"))
    ```

4. Read aloud (under your breath or in your head) the below code.
How intuitive is it to read?
Now re-write this code so you don't need to create the temporary `drug_use` object
by using the pipe,
then re-read the revised version. Which do you feel is easier to "read"?

    ```r
    drug_use <- select(NHANES, Marijuana, AgeFirstMarij)
    rename(drug_use, AgeOfFirstMarijuanaUse = AgeFirstMarij)
    ```
5. Add and commit to the Git history with the RStudio Git Interface.     
    
<details><summary><strong>Click for the solution</strong></summary>
<p>

```{r solution-ex-practice-dplyr, eval=FALSE}
# 1. Select specific columns
NHANES %>%
    select(HomeOwn, TVHrsDay, Diabetes)

# 2. Rename columns
NHANES %>%
    rename(DiabetesAgeOfDiagnosis = DiabetesAge, Sex = Gender)

# 3. Re-write with pipe
NHANES %>% 
    select(BMI, contains("Age"))

# 4. Re-write with pipe
NHANES %>% 
    select(Marijuana, AgeFirstMarij) %>% 
    rename(AgeOfFirstMarijuanaUse = AgeFirstMarij)
```

</p>
</details>

## Filter the data by row

Filtering data by row is a very common activity in data analysis, 
for example, to get rid of outliers or to subset by a categorical group. 
As with the previous functions, the function to subset/filter is called `filter()`. `filter()` is distinct from `select()` in the sense that it operates on rows whereas `select()` operates on columns. 
The `filter()` function takes a logic condition (`TRUE` or `FALSE`).
As with the other functions, the first position argument is the dataset,
and all others are logic conditions to use.
With `filter()`, when the logic conditions equals `TRUE`,
that means it **keeps** the rows that equal `TRUE` 
and *drop* those that are `FALSE`.

*A warning*: Since `filter()` uses logical conditions,
you need to be really careful when writing the logic.
As you probably know, humans are really really bad at logic.
So if your logical condition starts getting even a little complex,
double and triple check that you know your logic code is doing what you think it is.
It's very easy to make mistakes at this stage, even for advanced R users.

The simplest kind of logic condition is to test for "equality". 
In R, "equal to" is represented by `==`.
For example, if we want to keep only females in the dataset it would be:

```{r}
nhanes_small %>%
    filter(sex == "female")
```

We'd "read" this code as:

> Take the NHANES dataset, *and then* 
filter so that only rows where `Sex` is equal to "female" are kept.

So, when a row in the `Sex` column has the value "female", that row is kept.
Otherwise, it is dropped.

There are other logic comparisons to use.
Use Table \@ref(tab:logic-operators) as a reference for logical conditions in R.

```{r logic-operators, echo=FALSE}
tibble::tribble(
    ~Operator, ~ Description,
    "<", "less than",
    "<=", "less than or equal to",
    ">", "greater than",
    ">=", "greater than or equal to",
    "==", "equal to",
    "!=", "not equal to",
    "!x", "Not x (if x is true or false)",
    "x | y", "x OR y",
    "x & y", "x AND y"
) %>% 
    kable(caption = "Logical operators in R.")
```

Let's try out a few of these logic conditions with `filter()`.

```{r}
# Participants that don't have female sex
nhanes_small %>%
    filter(sex != "female")

# Participants that have BMI equal to 25
nhanes_small %>%
    filter(bmi == 25)

# Participants that have BMI equal to or more than 25
nhanes_small %>%
    filter(bmi >= 25)
```

We use the `|` ("or") and `&` ("and") when we want to combine conditions across columns.
Be especially careful with these operators and whenever combining logic conditions,
as they can sometimes work differently than our human brains interpret them
(speaking from experience).
For `&`, both sides must be `TRUE` in order for the combination to be `TRUE`.
For `|`, only one side needs to be `TRUE` in order for the combination to be `TRUE`.
To see how they work try these:

```{r}
TRUE & TRUE
TRUE & FALSE
FALSE & FALSE
TRUE | TRUE
TRUE | FALSE
FALSE | FALSE
```


```{r}
# when BMI is 25 AND sex is female
nhanes_small %>%
    filter(bmi == 25 & sex == "female")

# when BMI is 25 OR sex is female
nhanes_small %>%
    filter(bmi == 25 | sex == "female")
```

## (Re)Arranging the rows of your data by column

You may want to sort your rows by a specific column so that rows
are arranged with bigger (or smaller) values on top.
Arranging is done by using `arrange()`.
Again, `arrange()` takes the dataset as the first argument
and anything else it uses as the columns to order by.
By default, arrange orders in ascending order.

```{r}
# ascending order by age
nhanes_small %>%
    arrange(age)
```

It also arranges parameters of type character alphabetically:

```{r}
NHANES %>% 
    select(HealthGen) %>% 
    arrange(HealthGen)
```
We're selecting the parameter HealthGen first so we can show what is happening in the large dataset. 

We can do this also in descending order with `desc()`.

```{r}
# descending order
nhanes_small %>%
    arrange(desc(age))
```

You can also arrange by multiple columns. For instance,
first arrange by `sex` and then by `age`.

```{r}
# ascending order by sex and Age
nhanes_small %>%
    arrange(sex, age)
```

## Transform or add columns

To "transform" (modify) an existing column or to add a new one, the function to use is called `mutate()`. Unfortunately, unlike the other functions, the name is not as obvious about what it does. The meaning of mutate though is to change or modify, so it kind of makes sense. You would use `mutate()` if you wanted to compute a new variable using existing columns in your dataset, such as calculating BMI using `height` and `weight` columns. It may be that you want to multiply all values in a certain column by 2, or combine columns into a new variable. Like the other functions, the first input is the data and the other arguments are columns to add or modify.

The form that `mutate()` uses is similar to normal R assignment:
For instance, since the height's values are in centimeters, 
maybe we'd rather want them in meters. So, in `mutate()` we'd type out:

```
height = height / 100
```

This form is similar to how math works. 
The action that happens on the right hand side 
is put into the variable of the left hand side.
With using `mutate()` itself:

```{r}
nhanes_small %>%
    mutate(height = height / 100)
```

Or we can create a new column (maybe log transforming height):

```{r}
nhanes_small %>% 
    mutate(logged_height = log(height))
```

We can also add multiple modifications 
or additions with mutate by separating with `,`.
So if we first wanted to have height as meters and then take the natural logarithm, 
it would be:

```{r}
nhanes_small %>% 
    mutate(height = height / 100,
           logged_height = log(height))
```

We can also have different values based on a logic conditions using `if_else()`.
Use Table \@ref(tab:logic-operators) to help with creating the logic condition.

```{r}
nhanes_small %>%
    mutate(highly_active = if_else(phys_active_days >= 5, "yes", "no"))
```

Recall that the original dataset doesn't change. 
If we want the added variable to be included we must assign it to something with `<-`.
So putting it all together:

```{r}
nhanes_update <- nhanes_small %>%
    mutate(height = height / 100,
           logged_height = log(height),
           highly_active = if_else(phys_active_days >= 5, "Yes", "No"))
```

Before you start the exercise, add and commit all added lines to the Git history with the RStudio Git Interface.

## Exercise: Piping, filtering, and mutating

Time: 20 min

Copy and paste the code below into the script `exercises-wrangling.R`. 
Then start replacing the `___` with the appropriate
code to complete the tasks below.
(*Suggestion*: Create a new "Section"
in the R script for this exercise by using `Ctrl-Shift-R`).

1. Filter `nhanes_small` so only those with a BMI of more than or equal to 20 
*and* less than or equal to 40 *and* keep those who have diabetes.
2. Using the larger NHANES dataframe, create a new variable called `Urine_vol_average` by calculating the average
urine volumne (from `UrineVol1` and `UrineVol2`).
    - *Comment*: After creating the `urine_vol_average` column, 
    check out values. What do you notice? Compare with the original urine columns.
3. Create a new variable called `young_child` when age is less than 6 years.
4. Add and commit to the Git history with the RStudio Git Interface.

```{r ex-pipe-filter-mutate, eval=FALSE}
# 1. BMI between 20 and 40 and who have diabetes
nhanes_small %>%
    # format: variable >= number or character
    filter(___ >= ___ & ___ <= ___ & ___ == ___)

# Pipe the data into mutate function and:
nhanes_modified <- ___ %>% # dataset
    mutate(
        # 2. Calculate average urine volume
        ___ = ___,
        # 3. Create Young_child variable using a condition
        ___ = if_else(___, "Yes", "No")
    )
NHANES_modified
```

<details><summary><strong>Click for a possible solution</strong></summary>
<p>

```{r solution-ex-pipe-filter-mutate, eval=FALSE}
# 1. BMI between 20 and 40 and who have diabetes
nhanes_small %>%
    # format: variable >= number
    filter(bmi >= 20 & bmi <= 40 & diabetes == "Yes")

# Pipe the data into mutate function and:
NHANES_modified <- NHANES %>% # dataset
    mutate(
        # 2. Calculate average urine volume
        urine_vol_average = (UrineVol1 + UrineVol2) / 2,
        # 3. Create Young_child variable using a condition
        young_child = if_else(Age < 6, "Yes", "No")
    )
```

For the "urine_vol_average" values, they are probably almost entirely `NA` (aka
missing). That's because `NA` values are infectious. See how "UrineVol2" has mostly
`NA` values too? When you calculate something that has `NA`, you get another `NA`.
This is something to be careful about. So always check your calculations!

</p>
</details>

## Split-apply-combine: Summarizing data

**Take 5 min to read through parts of this section**, 
before we continue.

Summarizing or applying simple (or complex) statistics to data is 
(obviously) a key component of any analysis.
Simple summaries or statistics can be done either on all the data 
or on groups of it.
There are many data analysis tasks that can be approached 
using the [split-apply-combine] method:
split the data into groups, apply some analysis to each group,
and then combine the results together. 

[split-apply-combine]: https://www.jstatsoft.org/article/view/v040i01

In dplyr, to summarize on all the data, you would use the function `summarize()`.
If you want to do a split-apply-combine 
(e.g. find the max height of females and males) analysis,
you would use the functions `group_by()` and then `summarize()`.
Using `group_by()` splits the data up and
`summarise()` then applies an analysis 
and immediately combines it back together. 

The first position arguments to `group_by()` is, as usual, the dataset.
The next arguments are the columns that contain the values you want to group by.
These columns must contain **categorical** data (e.g. Sex). `group_by()` tells R to compute the summary operation that follows on a certain variable of interest. On its own, `group_by()` does nothing but instead works with other functions. For example, `group_by()` works in combination with `mutate()` too.

As with the other functions, 
`summarise()` takes the data as the first position argument.
The next arguments work similar to `mutate()` with one difference:
the output must create a single value (e.g. a max or a mean).
Like `mutate()`, 
you can add multiple "summaries" by adding new columns separated by comma `,`. You would use `summarize()` to derive basic descriptive statistics of a certain variable, including `min()`, `max()`, `mean()`, `median()`, `sd()`.

The `group_by()` function doesn't do anything by itself so should always be used in combination with a `summarize()`, `mutate()`, `arrange()`, or other function. However, the `summarize()` function can be used on its own. Let's take a look.

Add and commit to the Git history with the RStudio Git Interface.

## Calculating summary statistics

Let's calculate the max age. Because `NA` values "propagate" 
(if there is one missing, then a max or mean will be missing),
we need to tell `max()` to exclude `NA` using `na.rm = TRUE`.

```{r}
nhanes_small %>%
    summarize(max_age = max(age, na.rm = TRUE))
```

Add another summary column with `,`.

```{r}
nhanes_small %>%
    summarize(max_age = max(age, na.rm = TRUE),
              min_age = min(age, na.rm = TRUE))
```
Before you start the exercise, addd and commit to the Git history with the RStudio Git Interface.

## Exercise: Use `summarize()` to calculate basic statistics

Time: 10 min 

Practice using `summarize()` by calculating various summary statistics.
Complete the following tasks:

1. Calculate the `mean()` of `weight` and `bmi`.
2. Calculate the `max()` and `min()` of `height`.
3. Calculate the `median()` of `age` and `phys_active_days`.
4. Add and commit to the Git history with the RStudio Git Interface.

Don't forget to use `na.rm = TRUE` in the basic statistic functions.

```{r exercise-summarize-basic-stats, eval=FALSE}
# 1.
nhanes_small %>%
    summarize(mean_weight = ___,
              mean_bmi = ___)

# 2.
nhanes_small %>%
    summarize(max_height = ___,
              min_height = ___)

# 3.
nhanes_small %>%
    summarize(___ = ___,
              ___ = ___)
```

```{r solution-exercise-summarize-basic-stats, eval=FALSE, echo=FALSE}
# 1.
nhanes_small %>%
    summarize(mean_weight = mean(weight, na.rm = TRUE),
              mean_bmi = mean(bmi, na.rm = TRUE))

# 2.
nhanes_small %>%
    summarize(max_height = max(height, na.rm = TRUE),
              min_height = min(height, na.rm = TRUE))

# 3.
nhanes_small %>%
    summarize(median_age = median(height, na.rm = TRUE),
              median_phys_active_days = median(phys_active_days, na.rm = TRUE))             
```

## Summary statistics by a group

While the `summarize()` function is partly useful, it really shines when combined with `group_by()`.
Let's find out the mean age and BMI between those with and without Diabetes.

```{r}
nhanes_small %>%
    group_by(diabetes) %>% 
    summarise(mean_age = mean(age, na.rm = TRUE),
              mean_bmi = mean(bmi, na.rm = TRUE))
```

*Quick note*: If you are using dplyr version 1.0.0 (the latest),
you'll get a message informing you that it is `regrouping output`.
This is simply a message and can be ignored.
If you don't want the message displayed,
write `options(dplyr.summarise.inform = FALSE)` at the top of your script
and run it.

We get a warning about there being missing values in Diabetes, 
so let's first remove rows that have missing Diabetes status.

```{r}
nhanes_small %>%
    # Recall ! means "NOT", so !is.na means "is not missing"
    filter(!is.na(diabetes)) %>% 
    group_by(diabetes) %>% 
    summarise(mean_age = mean(age, na.rm = TRUE),
              mean_bmi = mean(bmi, na.rm = TRUE))
```

Cool! But we can add more columns to the grouping. 
Let's compare mean age and BMI by sex and diabetes status.

```{r}
nhanes_small %>%
    filter(!is.na(diabetes)) %>% 
    group_by(diabetes, sex) %>% 
    summarise(mean_age = mean(age, na.rm = TRUE),
              mean_bmi = mean(bmi, na.rm = TRUE))
```
Before you start the exercise, add and commit to the Git history with the RStudio Git Interface. 

Let's stay in the realm of diabetes and try to examine the differences between groups a little further.

## Exercise: Use `group_by()` and `summarize()` to answer some questions

Time: 5-7 min

Using the `group_by()` with `summarize()`, answer these questions:

1. What is the mean, max, and min differences in age between
females and males with or without diabetes?
2. What is the mean, max, and min differences in height and weight between
females and males with or without diabetes?
3. Add and commit to the Git history with the RStudio Git Interface. 

```{r exercise-groupby-summarise, eval=FALSE}
# 1. 
nhanes_small %>% 
    filter(!is.na(diabetes)) %>% 
    ___(___, ___) %>% 
    ___(
        ___,
        ___,
        ___
    )

# 2. 
nhanes_small %>% 
    filter(!is.na(diabetes)) %>% 
    ___(___, ___) %>% 
    ___(
        ___,
        ___,
        ___,
        ___,
        ___,
        ___
    )
```

```{r solution-exercise-groupby-summarise, eval=FALSE, echo=FALSE}
# 1. 
nhanes_small %>% 
    filter(!is.na(diabetes)) %>% 
    group_by(diabetes, sex) %>% 
    summarize(
        mean_age = mean(age, na.rm = TRUE),
        max_age = max(age, na.rm = TRUE),
        min_age = min(age, na.rm = TRUE),
    )

# 2. 
nhanes_small %>% 
    filter(!is.na(diabetes)) %>% 
    group_by(diabetes, sex) %>% 
    summarize(
        mean_height = mean(height, na.rm = TRUE),
        max_height = max(height, na.rm = TRUE),
        min_height = min(height, na.rm = TRUE),
        mean_weight = mean(weight, na.rm = TRUE),
        max_weight = max(weight, na.rm = TRUE),
        min_weight = min(weight, na.rm = TRUE)
    )
```

## Where have we gone wrong?

**Do this section on your own for the next 5 minutes**.
We are going to take a pitstop here to practice what you learned earlier \@ref(01-project-management.Rmd) about troubleshooting errors, including going back to the start of the code and running each line or part one at a time until you find where the problem occurs.

Here is a piece of code similar to the one we were just using. When it is run in RStudio, it returns an error message. However, we can’t immediately see the problem and need a hint to locate where in the code the issue lies. We are going to try the one-line-at-a-time approach.

```{r, error = TRUE}
nhanes_small %>%
    filter(!is.na(diabetes)) %>% 
    group_by(diabetes, sex) 
    summarise(mean_age = mean(age, na.rm = TRUE))
```

When you are working with pieces of code that uses pipes (%>%), you should highlight from one pipe up until (but excluding) the next pipe. Watch as each line of code is entered separately.

```{r}
nhanes_small %>%
    filter(!is.na(diabetes))
```

No problems there!

```{r}
nhanes_small %>%
    filter(!is.na(diabetes)) %>% 
    group_by(diabetes, sex) 
```

Again, no problems!

```{r, error = TRUE}
nhanes_small %>%
    filter(!is.na(diabetes)) %>% 
    group_by(diabetes, sex) 
    summarise(mean_age = mean(age, na.rm = TRUE))
```

Here is where the error occurs, which indicates that the issues lies somewhere between the `group_by()` and `summarise()` functions. If we take a closer look, you can see that the pipe was left off after the `group_by()` function line.

## Saving datasets as files

Sometimes you'll need or want to save the dataset you've been working on,
maybe because you've done a lot of cleaning to it, 
preparing it for later analyses, 
or because you've run an analysis and want to save the results.
Either way, 
a recommended way of saving your dataset is to use the `usethis::use_data()` function.
Let's do a very simple example:

```{r, eval=FALSE}
usethis::use_data(nhanes_small, overwrite = TRUE)
```

The `usethis::use_data()` function outputs some information, 
the last of which ("Document your data") we won't cover in this course.
The function takes any number of datasets 
and saves each individually as a `.rda` R dataset file in the `data/` folder.
You load the dataset and use it again, 
but before we do, let's restart the R session with either `Ctrl-Shift-F10`
or with the menu item "Session -> Restart R". Now, type out and run this:

```{r, eval=FALSE}
load(here::here("data/nhanes_small.rda"))
```

You should see this dataset in the Environment tab. 
This is how you save and load data.

## Loading in a dataset

**Take ~5 mins to read through this section**. You will get to practice loading
in a dataset in your group work session.

We've so far been using a teaching dataset that we load from a package, mainly
to focus on getting familiar with data wrangling. However, there will come a
time when you want to wrangle your own data.

There are several ways to load in a dataset. The most common ways are:

1. Using the RStudio menu "File -> Import Dataset -> From Text/Excel/SPSS/SAS/Stata" 
(depending on your file type you want to import). Copy and paste the R code given
for importing into the R script you are working in.

2. If the file is a `.csv` file, use `readr::read_csv()` to import the dataset:

    ```r
    dataset_name <- readr::read_csv(here::here("data/dataset_name.csv"))
    ```

3. If the dataset is a `.rda` file, use `load()`:

    ```r
    load(here::here("data/dataset_name.rda"))    
    ```


Before you start with the final exercise, add and commit to the Git history with the RStudio Git Interface. 

For SAS, SPSS, or Stata files, you can use the package 
[`haven`](https://haven.tidyverse.org/) to import those datasets into R.

## Summary of session {#wrangling-summary}

- In tidy data, each variable has its now column, each observation has its own row, and each value has its own cell
- Use the R package tidyverse to load in multiple packages to tidy up data 
- Never edit raw data - instead, save the changes in a separate folder or even file based on a code, and don't manually edit the data
- Use the functions `select()`, `rename()`, `filter()`, `mutate()` ("change or modify"), `arrange()` and `summarise()` your data from the dplyr package
- Use the pipe (`%>%`) to get an easy-to-read code, similar to reading a text consisting of multiple sentences

## Final exercise: Practicing the dplyr functions

Time: 30 minutes

In this exercise, you have the chance to through the content of the whole dplyr 
section yourself and solve a more challenging exercise. 
Complete these tasks by starting from the original `NHANES` dataset and using the
pipe to link each task with the next.

1. Rename all the columns so they are snake case.
2. Select columns gender, age and BMI.
3. Exclude NAs from all the selected columns.
4. Rename gender to sex.
5. Create a new column named `age_class`, where anyone under 50 years old is
labeled `"under 50"` and those 50 years old and older are labeled `"over 50"`.
6. Group the data according to `sex` and `age_class`.
7. Calculate the mean and median BMI according to the grouping to determine the
difference in BMI between age classes and sex.
8. Add and commit to the Git history with the RStudio Git Interface. 


<details><summary><strong>Click for the solution</strong></summary>
<p>

```{r solution-exercise-combine-all-dplyr, eval=FALSE}


NHANES %>% 
    rename_with(snakecase::to_snake_case) %>% select(gender, age,  bmi) %>% 
    filter(!is.na(gender) && !is.na(age) && !is.na(bmi)) %>% 
    rename(sex = gender) %>% 
    mutate(age_class = if_else(age < 50, "under50", "over50")) %>%
    group_by(age_class, sex) %>% 
    summarise(bmi_mean = mean(bmi, na.rm = TRUE), 
              bmi_median = median(bmi, na.rm = TRUE))
```

</p>
</details>
